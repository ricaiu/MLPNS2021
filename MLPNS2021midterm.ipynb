{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di MLPNS2021midterm_instructions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricaiu/MLPNS2021/blob/main/MLPNS2021midterm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tbkzMAe8atQ"
      },
      "source": [
        "#MLPNS 2021 midterm\n",
        "\n",
        "## instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO2n25U9uel0"
      },
      "source": [
        "# population trends by country through clustering analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmn-7suu2MUl"
      },
      "source": [
        "# Please read in full before you start!\n",
        "\n",
        "This exercise combines the two machine learning methods that you have learned so far in this course: linear regression and clustering. \n",
        "\n",
        "There are multiple tasks and for some of them, **if you cannot complete the taks,  there are partial solutions you can access** so you donâ€™t get stuck and can continue the exercise and demonstrate your ability to do the following tasks. I strongly encourage you to do so: there are 10 tasks and you only have ~2 hours! If any task takes you more than 20 minutes you should use the shortcut.\n",
        "\n",
        "I have collected from the World Bank database population grows time series for several countries. \n",
        "\n",
        "## The overall goal is to identify countries that have similar population growth trends over the years and possibly countries that have anomalous population growth. \n",
        "\n",
        "You will be guided to \n",
        "- acquire the data, \n",
        "- explore it and prepare it, \n",
        "- fit a linear model to the each time series, \n",
        "- use the parameters you obtain from that fit as input feature to K-means clustering to group countries based on the trends in the population growth. \n",
        "- You will also be asked to look inside the group and if you have time identify reasons why the Countries within the clusters that may suggest why the trends are similar (thiw sill be very speculative of course)\n",
        "\n",
        "**Make sure you show the characteristics of your data at every step** (by printing the shape of the data, the head of the data, the summary statistics of the data, or plot the data, whichever is apprioriate). \n",
        "\n",
        "**Every plot needs to have axis labels and a caption that describes what is being plotted and what should be noted in the plot** (e.g. global trends in the time series)\n",
        "\n",
        "Your \"grade\" will be based on the rendered notebook, i.e. on the summary a tables and the plots as I see them and the captions that describe them (the captions can be markdown cells in the notebook).\n",
        "\n",
        "After grading your notebook based on the rendered version I will restart it and run it. If it runs and produces  identical results you will get 100% of the points awarded in the previous step. Otherwise you will get 75%. **Make sure you stop a few minutes before the time expires to rerun the notebook!**\n",
        "\n",
        "## feel free to ask question on zoom or on slack!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E7s1FM5PkHC"
      },
      "source": [
        "# these are all the packages I used. But depending on your choices you may need more or other ones. That is ok!\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "from sklearn.cluster  import KMeans\n",
        "import scipy.optimize\n",
        "\n",
        "\n",
        "pl.rcParams['font.size'] = 18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO9RSHbeX6Jt"
      },
      "source": [
        "\n",
        "# PART 1 - data preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXfKxHTWuZdV"
      },
      "source": [
        "\n",
        "\n",
        "# TASK 1.I - read in the data\n",
        "the data is available in format _excel_ [here](https://github.com/fedhere/MLPNS2021/tree/main/midterm) called _country_pop.xls_\n",
        "\n",
        "Pandas has a function, similar to ```read_csv()``` which you used in class, called ```read_excel()```. Download the data in your drive and read it in with this function. You can either download it and read it from your drive. Please put it in a folder My\\ Drive/MLPNS (so that I can run the notebook seamlessly without having to change the path since I have the file stored in My\\ Drive/MLPNS). \n",
        "\n",
        "At the end the file should look like mine below. You should not spend more than 20 minutes on this or you will not have enough time to finish. If after 20 minutes you are still working on it consider using the shortcut\n",
        "\n",
        "## shortcut: \n",
        "if you have troubles reading in the original file with excel you can read in a csv file [here](https://github.com/fedhere/MLPNS2021/tree/main/midterm): the file is called _country_pop.csv_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "fWX4PW65qeg0",
        "outputId": "049e7aa9-1ba7-4b8d-df8f-2f062e49f4b4"
      },
      "source": [
        "#leave\n",
        "datain.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1960.0</th>\n",
              "      <th>1961.0</th>\n",
              "      <th>1962.0</th>\n",
              "      <th>1963.0</th>\n",
              "      <th>1964.0</th>\n",
              "      <th>1965.0</th>\n",
              "      <th>1966.0</th>\n",
              "      <th>1967.0</th>\n",
              "      <th>1968.0</th>\n",
              "      <th>1969.0</th>\n",
              "      <th>1970.0</th>\n",
              "      <th>1971.0</th>\n",
              "      <th>1972.0</th>\n",
              "      <th>1973.0</th>\n",
              "      <th>1974.0</th>\n",
              "      <th>1975.0</th>\n",
              "      <th>1976.0</th>\n",
              "      <th>1977.0</th>\n",
              "      <th>1978.0</th>\n",
              "      <th>1979.0</th>\n",
              "      <th>1980.0</th>\n",
              "      <th>1981.0</th>\n",
              "      <th>1982.0</th>\n",
              "      <th>1983.0</th>\n",
              "      <th>1984.0</th>\n",
              "      <th>1985.0</th>\n",
              "      <th>1986.0</th>\n",
              "      <th>1987.0</th>\n",
              "      <th>1988.0</th>\n",
              "      <th>1989.0</th>\n",
              "      <th>1990.0</th>\n",
              "      <th>1991.0</th>\n",
              "      <th>1992.0</th>\n",
              "      <th>1993.0</th>\n",
              "      <th>1994.0</th>\n",
              "      <th>1995.0</th>\n",
              "      <th>1996.0</th>\n",
              "      <th>1997.0</th>\n",
              "      <th>1998.0</th>\n",
              "      <th>1999.0</th>\n",
              "      <th>2000.0</th>\n",
              "      <th>2001.0</th>\n",
              "      <th>2002.0</th>\n",
              "      <th>2003.0</th>\n",
              "      <th>2004.0</th>\n",
              "      <th>2005.0</th>\n",
              "      <th>2006.0</th>\n",
              "      <th>2007.0</th>\n",
              "      <th>2008.0</th>\n",
              "      <th>2009.0</th>\n",
              "      <th>2010.0</th>\n",
              "      <th>2011.0</th>\n",
              "      <th>2012.0</th>\n",
              "      <th>2013.0</th>\n",
              "      <th>2014.0</th>\n",
              "      <th>2015.0</th>\n",
              "      <th>2016.0</th>\n",
              "      <th>2017.0</th>\n",
              "      <th>2018.0</th>\n",
              "      <th>2019.0</th>\n",
              "      <th>2020.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Source</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Aruba</th>\n",
              "      <td>54211.0</td>\n",
              "      <td>55438.0</td>\n",
              "      <td>56225.0</td>\n",
              "      <td>56695.0</td>\n",
              "      <td>57032.0</td>\n",
              "      <td>57360.0</td>\n",
              "      <td>57715.0</td>\n",
              "      <td>58055.0</td>\n",
              "      <td>58386.0</td>\n",
              "      <td>58726.0</td>\n",
              "      <td>59063.0</td>\n",
              "      <td>59440.0</td>\n",
              "      <td>59840.0</td>\n",
              "      <td>60243.0</td>\n",
              "      <td>60528.0</td>\n",
              "      <td>60657.0</td>\n",
              "      <td>60586.0</td>\n",
              "      <td>60366.0</td>\n",
              "      <td>60103.0</td>\n",
              "      <td>59980.0</td>\n",
              "      <td>60096.0</td>\n",
              "      <td>60567.0</td>\n",
              "      <td>61345.0</td>\n",
              "      <td>62201.0</td>\n",
              "      <td>62836.0</td>\n",
              "      <td>63026.0</td>\n",
              "      <td>62644.0</td>\n",
              "      <td>61833.0</td>\n",
              "      <td>61079.0</td>\n",
              "      <td>61032.0</td>\n",
              "      <td>62149.0</td>\n",
              "      <td>64622.0</td>\n",
              "      <td>68235.0</td>\n",
              "      <td>72504.0</td>\n",
              "      <td>76700.0</td>\n",
              "      <td>80324.0</td>\n",
              "      <td>83200.0</td>\n",
              "      <td>85451.0</td>\n",
              "      <td>87277.0</td>\n",
              "      <td>89005.0</td>\n",
              "      <td>90853.0</td>\n",
              "      <td>92898.0</td>\n",
              "      <td>94992.0</td>\n",
              "      <td>97017.0</td>\n",
              "      <td>98737.0</td>\n",
              "      <td>100031.0</td>\n",
              "      <td>100834.0</td>\n",
              "      <td>101222.0</td>\n",
              "      <td>101358.0</td>\n",
              "      <td>101455.0</td>\n",
              "      <td>101669.0</td>\n",
              "      <td>102046.0</td>\n",
              "      <td>102560.0</td>\n",
              "      <td>103159.0</td>\n",
              "      <td>103774.0</td>\n",
              "      <td>104341.0</td>\n",
              "      <td>104872.0</td>\n",
              "      <td>105366.0</td>\n",
              "      <td>105845.0</td>\n",
              "      <td>106314.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Afghanistan</th>\n",
              "      <td>8996973.0</td>\n",
              "      <td>9169410.0</td>\n",
              "      <td>9351441.0</td>\n",
              "      <td>9543205.0</td>\n",
              "      <td>9744781.0</td>\n",
              "      <td>9956320.0</td>\n",
              "      <td>10174836.0</td>\n",
              "      <td>10399926.0</td>\n",
              "      <td>10637063.0</td>\n",
              "      <td>10893776.0</td>\n",
              "      <td>11173642.0</td>\n",
              "      <td>11475445.0</td>\n",
              "      <td>11791215.0</td>\n",
              "      <td>12108963.0</td>\n",
              "      <td>12412950.0</td>\n",
              "      <td>12689160.0</td>\n",
              "      <td>12943093.0</td>\n",
              "      <td>13171306.0</td>\n",
              "      <td>13341198.0</td>\n",
              "      <td>13411056.0</td>\n",
              "      <td>13356511.0</td>\n",
              "      <td>13171673.0</td>\n",
              "      <td>12882528.0</td>\n",
              "      <td>12537730.0</td>\n",
              "      <td>12204292.0</td>\n",
              "      <td>11938208.0</td>\n",
              "      <td>11736179.0</td>\n",
              "      <td>11604534.0</td>\n",
              "      <td>11618005.0</td>\n",
              "      <td>11868877.0</td>\n",
              "      <td>12412308.0</td>\n",
              "      <td>13299017.0</td>\n",
              "      <td>14485546.0</td>\n",
              "      <td>15816603.0</td>\n",
              "      <td>17075727.0</td>\n",
              "      <td>18110657.0</td>\n",
              "      <td>18853437.0</td>\n",
              "      <td>19357126.0</td>\n",
              "      <td>19737765.0</td>\n",
              "      <td>20170844.0</td>\n",
              "      <td>20779953.0</td>\n",
              "      <td>21606988.0</td>\n",
              "      <td>22600770.0</td>\n",
              "      <td>23680871.0</td>\n",
              "      <td>24726684.0</td>\n",
              "      <td>25654277.0</td>\n",
              "      <td>26433049.0</td>\n",
              "      <td>27100536.0</td>\n",
              "      <td>27722276.0</td>\n",
              "      <td>28394813.0</td>\n",
              "      <td>29185507.0</td>\n",
              "      <td>30117413.0</td>\n",
              "      <td>31161376.0</td>\n",
              "      <td>32269589.0</td>\n",
              "      <td>33370794.0</td>\n",
              "      <td>34413603.0</td>\n",
              "      <td>35383128.0</td>\n",
              "      <td>36296400.0</td>\n",
              "      <td>37172386.0</td>\n",
              "      <td>38041754.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Angola</th>\n",
              "      <td>5454933.0</td>\n",
              "      <td>5531472.0</td>\n",
              "      <td>5608539.0</td>\n",
              "      <td>5679458.0</td>\n",
              "      <td>5735044.0</td>\n",
              "      <td>5770570.0</td>\n",
              "      <td>5781214.0</td>\n",
              "      <td>5774243.0</td>\n",
              "      <td>5771652.0</td>\n",
              "      <td>5803254.0</td>\n",
              "      <td>5890365.0</td>\n",
              "      <td>6040777.0</td>\n",
              "      <td>6248552.0</td>\n",
              "      <td>6496962.0</td>\n",
              "      <td>6761380.0</td>\n",
              "      <td>7024000.0</td>\n",
              "      <td>7279509.0</td>\n",
              "      <td>7533735.0</td>\n",
              "      <td>7790707.0</td>\n",
              "      <td>8058067.0</td>\n",
              "      <td>8341289.0</td>\n",
              "      <td>8640446.0</td>\n",
              "      <td>8952950.0</td>\n",
              "      <td>9278096.0</td>\n",
              "      <td>9614754.0</td>\n",
              "      <td>9961997.0</td>\n",
              "      <td>10320111.0</td>\n",
              "      <td>10689250.0</td>\n",
              "      <td>11068050.0</td>\n",
              "      <td>11454777.0</td>\n",
              "      <td>11848386.0</td>\n",
              "      <td>12248901.0</td>\n",
              "      <td>12657366.0</td>\n",
              "      <td>13075049.0</td>\n",
              "      <td>13503747.0</td>\n",
              "      <td>13945206.0</td>\n",
              "      <td>14400719.0</td>\n",
              "      <td>14871570.0</td>\n",
              "      <td>15359601.0</td>\n",
              "      <td>15866869.0</td>\n",
              "      <td>16395473.0</td>\n",
              "      <td>16945753.0</td>\n",
              "      <td>17519417.0</td>\n",
              "      <td>18121479.0</td>\n",
              "      <td>18758145.0</td>\n",
              "      <td>19433602.0</td>\n",
              "      <td>20149901.0</td>\n",
              "      <td>20905363.0</td>\n",
              "      <td>21695634.0</td>\n",
              "      <td>22514281.0</td>\n",
              "      <td>23356246.0</td>\n",
              "      <td>24220661.0</td>\n",
              "      <td>25107931.0</td>\n",
              "      <td>26015780.0</td>\n",
              "      <td>26941779.0</td>\n",
              "      <td>27884381.0</td>\n",
              "      <td>28842484.0</td>\n",
              "      <td>29816748.0</td>\n",
              "      <td>30809762.0</td>\n",
              "      <td>31825295.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Albania</th>\n",
              "      <td>1608800.0</td>\n",
              "      <td>1659800.0</td>\n",
              "      <td>1711319.0</td>\n",
              "      <td>1762621.0</td>\n",
              "      <td>1814135.0</td>\n",
              "      <td>1864791.0</td>\n",
              "      <td>1914573.0</td>\n",
              "      <td>1965598.0</td>\n",
              "      <td>2022272.0</td>\n",
              "      <td>2081695.0</td>\n",
              "      <td>2135479.0</td>\n",
              "      <td>2187853.0</td>\n",
              "      <td>2243126.0</td>\n",
              "      <td>2296752.0</td>\n",
              "      <td>2350124.0</td>\n",
              "      <td>2404831.0</td>\n",
              "      <td>2458526.0</td>\n",
              "      <td>2513546.0</td>\n",
              "      <td>2566266.0</td>\n",
              "      <td>2617832.0</td>\n",
              "      <td>2671997.0</td>\n",
              "      <td>2726056.0</td>\n",
              "      <td>2784278.0</td>\n",
              "      <td>2843960.0</td>\n",
              "      <td>2904429.0</td>\n",
              "      <td>2964762.0</td>\n",
              "      <td>3022635.0</td>\n",
              "      <td>3083605.0</td>\n",
              "      <td>3142336.0</td>\n",
              "      <td>3227943.0</td>\n",
              "      <td>3286542.0</td>\n",
              "      <td>3266790.0</td>\n",
              "      <td>3247039.0</td>\n",
              "      <td>3227287.0</td>\n",
              "      <td>3207536.0</td>\n",
              "      <td>3187784.0</td>\n",
              "      <td>3168033.0</td>\n",
              "      <td>3148281.0</td>\n",
              "      <td>3128530.0</td>\n",
              "      <td>3108778.0</td>\n",
              "      <td>3089027.0</td>\n",
              "      <td>3060173.0</td>\n",
              "      <td>3051010.0</td>\n",
              "      <td>3039616.0</td>\n",
              "      <td>3026939.0</td>\n",
              "      <td>3011487.0</td>\n",
              "      <td>2992547.0</td>\n",
              "      <td>2970017.0</td>\n",
              "      <td>2947314.0</td>\n",
              "      <td>2927519.0</td>\n",
              "      <td>2913021.0</td>\n",
              "      <td>2905195.0</td>\n",
              "      <td>2900401.0</td>\n",
              "      <td>2895092.0</td>\n",
              "      <td>2889104.0</td>\n",
              "      <td>2880703.0</td>\n",
              "      <td>2876101.0</td>\n",
              "      <td>2873457.0</td>\n",
              "      <td>2866376.0</td>\n",
              "      <td>2854191.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Andorra</th>\n",
              "      <td>13411.0</td>\n",
              "      <td>14375.0</td>\n",
              "      <td>15370.0</td>\n",
              "      <td>16412.0</td>\n",
              "      <td>17469.0</td>\n",
              "      <td>18549.0</td>\n",
              "      <td>19647.0</td>\n",
              "      <td>20758.0</td>\n",
              "      <td>21890.0</td>\n",
              "      <td>23058.0</td>\n",
              "      <td>24276.0</td>\n",
              "      <td>25559.0</td>\n",
              "      <td>26892.0</td>\n",
              "      <td>28232.0</td>\n",
              "      <td>29520.0</td>\n",
              "      <td>30705.0</td>\n",
              "      <td>31777.0</td>\n",
              "      <td>32771.0</td>\n",
              "      <td>33737.0</td>\n",
              "      <td>34818.0</td>\n",
              "      <td>36067.0</td>\n",
              "      <td>37500.0</td>\n",
              "      <td>39114.0</td>\n",
              "      <td>40867.0</td>\n",
              "      <td>42706.0</td>\n",
              "      <td>44600.0</td>\n",
              "      <td>46517.0</td>\n",
              "      <td>48455.0</td>\n",
              "      <td>50434.0</td>\n",
              "      <td>52448.0</td>\n",
              "      <td>54509.0</td>\n",
              "      <td>56671.0</td>\n",
              "      <td>58888.0</td>\n",
              "      <td>60971.0</td>\n",
              "      <td>62677.0</td>\n",
              "      <td>63850.0</td>\n",
              "      <td>64360.0</td>\n",
              "      <td>64327.0</td>\n",
              "      <td>64142.0</td>\n",
              "      <td>64370.0</td>\n",
              "      <td>65390.0</td>\n",
              "      <td>67341.0</td>\n",
              "      <td>70049.0</td>\n",
              "      <td>73182.0</td>\n",
              "      <td>76244.0</td>\n",
              "      <td>78867.0</td>\n",
              "      <td>80993.0</td>\n",
              "      <td>82684.0</td>\n",
              "      <td>83862.0</td>\n",
              "      <td>84463.0</td>\n",
              "      <td>84449.0</td>\n",
              "      <td>83747.0</td>\n",
              "      <td>82427.0</td>\n",
              "      <td>80774.0</td>\n",
              "      <td>79213.0</td>\n",
              "      <td>78011.0</td>\n",
              "      <td>77297.0</td>\n",
              "      <td>77001.0</td>\n",
              "      <td>77006.0</td>\n",
              "      <td>77142.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                1960.0     1961.0     1962.0  ...      2018.0      2019.0  2020.0\n",
              "Data Source                                   ...                                \n",
              "Aruba          54211.0    55438.0    56225.0  ...    105845.0    106314.0     NaN\n",
              "Afghanistan  8996973.0  9169410.0  9351441.0  ...  37172386.0  38041754.0     NaN\n",
              "Angola       5454933.0  5531472.0  5608539.0  ...  30809762.0  31825295.0     NaN\n",
              "Albania      1608800.0  1659800.0  1711319.0  ...   2866376.0   2854191.0     NaN\n",
              "Andorra        13411.0    14375.0    15370.0  ...     77006.0     77142.0     NaN\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxHdleAXyN7D"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#  TASK 1.II - clean the data\n",
        "\n",
        "how many rows and columns are in the data? how many missing values? missing values should be removed. If there are not many observations (=countries) with missing data the easiest solution is to remove the countries entirely. Use the dataframe method ```dropna``` to remove them. Otherwise, if you are brave, you can input values using the dataframe method fillna (good luck!). \n",
        "\n",
        "\n",
        "print the number of countries and the length of the timeline using the line of code provided _before_ and _after_ cleaning. State the percentage of observations lost\n",
        "\n",
        "## shortcut: \n",
        "\n",
        "You can download the dataframe with missing values removed by row [here](https://github.com/fedhere/MLPNS2021/tree/main/midterm): the file is called  _country_pop_clean.csv_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMMQf4edU0tF"
      },
      "source": [
        "print(\"there are {} countries and {} time stamps in the data\".\n",
        "      format(*datain.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHG9N1Mcsfcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a2991c-304f-4b5d-9ebe-457a019e9ac7"
      },
      "source": [
        "print(\"there are {} countries and {} time stamps in the cleaned data\".\n",
        "      format(*datain.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 258 countries and 60 time stamps in the cleaned data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkVKPIgZxs1r"
      },
      "source": [
        "# TASK 1.III - plot the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV1H9C0LTWqO"
      },
      "source": [
        "plot the original data. plot all the time series in the same panel. Optionally, also make the plot in log-y space to better see the collection of the data. Describe what you see (you can check my plots [here](https://github.com/fedhere/MLPNS2021/blob/main/midterm/firstFigure.png) - its not a pretty figure, but it is helpful in understanding a lot of characteristivcs of the data! Your figure does not have to look identical to mine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IdKfd3ks1FD"
      },
      "source": [
        "# TASK 1.IV - scale the data\n",
        "\n",
        "# Preprocessing\n",
        "Of course different countries have different population size. But we are only interested in the trends in these exercises, not in the overal size of the country. Thus before fitting a polynomial to the data you need to normalize the lightcurves: from each lightcurve you should remove the mean and divide by the standard deviation. You can do it by hand or you can use the ```preprocessing.scale``` function (there is an example of that in the slides https://slides.com/federicabianco/mlpns_4#/5/8)\n",
        "\n",
        "_Each time series should be mean 0 and stdev 1_\n",
        "\n",
        "I recommand working with a numpy array from here forward by extracting the values from the dataframe as ```X = df.values```\n",
        "\n",
        "**After scaling the data replot it.**\n",
        "\n",
        "## shortcut\n",
        "\n",
        "You can get the final dataset [here](https://github.com/fedhere/MLPNS2021/tree/main/midterm), its called _country_pop_final.csv_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMXZa10cYBek"
      },
      "source": [
        "# PART 2 - feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yg70oTxzZr2"
      },
      "source": [
        "\n",
        "\n",
        "# Task 2.I\n",
        "\n",
        "fit a second degree polynomial (```y = ax^2 + bx + c```) to each time series. Store the values of a,b,c for each time series in an array called ```features``` (I recommand using L2 for the fit and ```scipy.optimize.minimize```)\n",
        "\n",
        "For each feature test if the sample is consistent with coming from a normal distribution (with  NHRT test, e.g. we used the KS test in class for this purpose)\n",
        "\n",
        "**plot the histogram of each feature**\n",
        "\n",
        "Optional: also store the value of L2 for the best fit parameters. Then your feature space would be 4-dimensional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx30H9U90VNR",
        "outputId": "5fc3ba52-faae-4909-fa3c-d589d2898010"
      },
      "source": [
        "X = datain.values\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(258, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-4v7wZ32KHm",
        "outputId": "c2c020f8-5b8f-463a-9c51-d783114bb50b"
      },
      "source": [
        "...\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(258, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgIGVOBDX2fB"
      },
      "source": [
        "# PART 3 - modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbXEgXp_2RUp"
      },
      "source": [
        "\n",
        "# TASK 3.I - preprocess the features\n",
        "\n",
        "before you can use kmeans clusgtering you have to preprocess (scale) the features: all feature should have mean 0 and stdev 1 (you can again use sklearn.preprocess.scale (save the mean and stdev values... you will need the later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THpkBaZO2QkD",
        "outputId": "cbc16848-627e-47c2-fd2c-2439bdf50fec"
      },
      "source": [
        "...\n",
        "X2.std(axis=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUGnXne32qn"
      },
      "source": [
        "# TASK 2.III - choosing the number of clusters \n",
        "\n",
        "\n",
        "cluster the data using kmeans in 2, 3, ... up to 10 clusters and print the total variance for each cluster. \n",
        "\n",
        "Plot the total variance as a function of number of clusters. See https://slides.com/federicabianco/mlpns_4#/8/4\n",
        "\n",
        "Discuss the plot. Does it give insight into what is the the appropriate number of clusters?\n",
        "\n",
        "Choose a number of clusters and for that choice show the cluster centers.\n",
        "\n",
        "## shortcut\n",
        "\n",
        "the elbow plot does not help ... use 4 clusters\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP8Xf3wTWSyz"
      },
      "source": [
        "\n",
        "# TASK 2.IV - clustering\n",
        "\n",
        "\n",
        "Note: the cluster centers are datapoints in the feature space. If your feature space is 3D (3 coefficients, or four depending on what you choose in task 2.II) your cluster center is a tuple of numbers. \n",
        "\n",
        "**However, the right way to show the cluster centers is to**\n",
        "\n",
        "1- unscale the cluster centers by multiplying them by the stdev and adding back the mean \n",
        "\n",
        "2- plot the polynomial generated by those cluster centers\n",
        "\n",
        "3- plot the time series that belong to that cluster in the same plot.\n",
        "\n",
        "Print how many time series are in each cluster.\n",
        "\n",
        "To measure the intracluster compactness (to make the elbow plot that may help you decide how many clusters to plot use the attribute of the cluster model\n",
        "```kmeas_fit_model.inertia_```\n",
        "\n",
        "To extract the cluster centers use \n",
        "```kmeas_fit_model.cluster_centers_```\n",
        "\n",
        "To extract the cluster assignment for each time series use \n",
        "\n",
        "```kmeas_fit_model.labels_```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Ye65DPYGTC"
      },
      "source": [
        "# PART 4 - interpretation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-gd8Oz9VLln"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# TASK 4.I\n",
        "extract the name of the countries in the 2 smallest clusters. Is there anything in common that gives away why they may have the same trends? If you have time try a quick google search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6wn5DuR8EiT"
      },
      "source": [
        "datain.index[c.labels_ == ...]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}